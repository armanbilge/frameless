
<!DOCTYPE HTML>
<html lang="" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>Typed Encoders in Frameless Â· GitBook</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.3">
        
        
        
    
    <link rel="stylesheet" href="gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="Injection.html" />
    
    
    <link rel="prev" href="WorkingWithCsvParquetJson.html" />
    

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="Type to search" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="./">
            
                <a href="./">
            
                    
                    Introduction
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="FeatureOverview.html">
            
                <a href="FeatureOverview.html">
            
                    
                    TypedDataset: Feature Overview
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3" data-path="TypedDatasetVsSparkDataset.html">
            
                <a href="TypedDatasetVsSparkDataset.html">
            
                    
                    Comparing TypedDatasets with Spark's Datasets
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4" data-path="WorkingWithCsvParquetJson.html">
            
                <a href="WorkingWithCsvParquetJson.html">
            
                    
                    Working with CSV and Parquet
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="1.5" data-path="TypedEncoder.html">
            
                <a href="TypedEncoder.html">
            
                    
                    Typed Encoders in Frameless
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6" data-path="Injection.html">
            
                <a href="Injection.html">
            
                    
                    Injection: Creating Custom Encoders
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7" data-path="Job.html">
            
                <a href="Job.html">
            
                    
                    Job[A]
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.8" data-path="Cats.html">
            
                <a href="Cats.html">
            
                    
                    Using Cats with RDDs
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.9" data-path="TypedML.html">
            
                <a href="TypedML.html">
            
                    
                    Using Spark ML with TypedDataset
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10" data-path="TypedDataFrame.html">
            
                <a href="TypedDataFrame.html">
            
                    
                    Proof of Concept: TypedDataFrame
            
                </a>
            

            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            Published with GitBook
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href="." >Typed Encoders in Frameless</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h1 id="typed-encoders-in-frameless">Typed Encoders in Frameless</h1>
<p>Spark uses Reflection to derive its <code>Encoder</code>s, which is why they can fail at run time. For example, because Spark does not support <code>java.util.Date</code>, the following leads to an error:</p>
<pre><code class="lang-scala"><span class="hljs-keyword">import</span> org.apache.spark.sql.<span class="hljs-type">Dataset</span>
<span class="hljs-keyword">import</span> spark.implicits._

<span class="hljs-keyword">case</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">DateRange</span>(<span class="hljs-params">s: java.util.<span class="hljs-type">Date</span>, e: java.util.<span class="hljs-type">Date</span></span>)</span>
</code></pre>
<pre><code class="lang-scala"><span class="hljs-keyword">val</span> ds: <span class="hljs-type">Dataset</span>[<span class="hljs-type">DateRange</span>] = <span class="hljs-type">Seq</span>(<span class="hljs-type">DateRange</span>(<span class="hljs-keyword">new</span> java.util.<span class="hljs-type">Date</span>, <span class="hljs-keyword">new</span> java.util.<span class="hljs-type">Date</span>)).toDS()
<span class="hljs-comment">// java.lang.UnsupportedOperationException: No Encoder found for java.util.Date</span>
<span class="hljs-comment">// - field (class: &quot;java.util.Date&quot;, name: &quot;s&quot;)</span>
<span class="hljs-comment">// - root class: &quot;repl.MdocSession.App0.DateRange&quot;</span>
<span class="hljs-comment">//     at org.apache.spark.sql.catalyst.ScalaReflection$.$anonfun$serializerFor$1(ScalaReflection.scala:591)</span>
<span class="hljs-comment">//     at scala.reflect.internal.tpe.TypeConstraints$UndoLog.undo(TypeConstraints.scala:73)</span>
<span class="hljs-comment">//     at org.apache.spark.sql.catalyst.ScalaReflection.cleanUpReflectionObjects(ScalaReflection.scala:904)</span>
<span class="hljs-comment">//     at org.apache.spark.sql.catalyst.ScalaReflection.cleanUpReflectionObjects$(ScalaReflection.scala:903)</span>
<span class="hljs-comment">//     at org.apache.spark.sql.catalyst.ScalaReflection$.cleanUpReflectionObjects(ScalaReflection.scala:49)</span>
<span class="hljs-comment">//     at org.apache.spark.sql.catalyst.ScalaReflection$.serializerFor(ScalaReflection.scala:432)</span>
<span class="hljs-comment">//     at org.apache.spark.sql.catalyst.ScalaReflection$.$anonfun$serializerFor$6(ScalaReflection.scala:577)</span>
<span class="hljs-comment">//     at scala.collection.immutable.List.map(List.scala:293)</span>
<span class="hljs-comment">//     at org.apache.spark.sql.catalyst.ScalaReflection$.$anonfun$serializerFor$1(ScalaReflection.scala:562)</span>
<span class="hljs-comment">//     at scala.reflect.internal.tpe.TypeConstraints$UndoLog.undo(TypeConstraints.scala:73)</span>
<span class="hljs-comment">//     at org.apache.spark.sql.catalyst.ScalaReflection.cleanUpReflectionObjects(ScalaReflection.scala:904)</span>
<span class="hljs-comment">//     at org.apache.spark.sql.catalyst.ScalaReflection.cleanUpReflectionObjects$(ScalaReflection.scala:903)</span>
<span class="hljs-comment">//     at org.apache.spark.sql.catalyst.ScalaReflection$.cleanUpReflectionObjects(ScalaReflection.scala:49)</span>
<span class="hljs-comment">//     at org.apache.spark.sql.catalyst.ScalaReflection$.serializerFor(ScalaReflection.scala:432)</span>
<span class="hljs-comment">//     at org.apache.spark.sql.catalyst.ScalaReflection$.$anonfun$serializerForType$1(ScalaReflection.scala:421)</span>
<span class="hljs-comment">//     at scala.reflect.internal.tpe.TypeConstraints$UndoLog.undo(TypeConstraints.scala:73)</span>
<span class="hljs-comment">//     at org.apache.spark.sql.catalyst.ScalaReflection.cleanUpReflectionObjects(ScalaReflection.scala:904)</span>
<span class="hljs-comment">//     at org.apache.spark.sql.catalyst.ScalaReflection.cleanUpReflectionObjects$(ScalaReflection.scala:903)</span>
<span class="hljs-comment">//     at org.apache.spark.sql.catalyst.ScalaReflection$.cleanUpReflectionObjects(ScalaReflection.scala:49)</span>
<span class="hljs-comment">//     at org.apache.spark.sql.catalyst.ScalaReflection$.serializerForType(ScalaReflection.scala:413)</span>
<span class="hljs-comment">//     at org.apache.spark.sql.catalyst.encoders.ExpressionEncoder$.apply(ExpressionEncoder.scala:55)</span>
<span class="hljs-comment">//     at org.apache.spark.sql.Encoders$.product(Encoders.scala:285)</span>
<span class="hljs-comment">//     at org.apache.spark.sql.LowPrioritySQLImplicits.newProductEncoder(SQLImplicits.scala:251)</span>
<span class="hljs-comment">//     at org.apache.spark.sql.LowPrioritySQLImplicits.newProductEncoder$(SQLImplicits.scala:251)</span>
<span class="hljs-comment">//     at org.apache.spark.sql.SQLImplicits.newProductEncoder(SQLImplicits.scala:32)</span>
<span class="hljs-comment">//     at repl.MdocSession$App0$$anonfun$4.apply$mcV$sp(TypedEncoder.md:45)</span>
<span class="hljs-comment">//     at repl.MdocSession$App0$$anonfun$4.apply(TypedEncoder.md:44)</span>
<span class="hljs-comment">//     at repl.MdocSession$App0$$anonfun$4.apply(TypedEncoder.md:44)</span>
</code></pre>
<p>As shown by the stack trace, this runtime error goes through <a href="https://github.com/apache/spark/blob/19cf208063f035d793d2306295a251a9af7e32f6/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/ScalaReflection.scala" target="_blank">ScalaReflection</a> to try to derive an <code>Encoder</code> for <code>Dataset</code> schema. Beside the annoyance of not detecting this error at compile time, a more important limitation of the reflection-based approach is its inability to be extended for custom types. See this Stack Overflow question for a summary of the current situation (as of 2.0) in vanilla Spark: <a href="http://stackoverflow.com/a/39442829/2311362" target="_blank">How to store custom objects in a Dataset?</a>.</p>
<p>Frameless introduces a new type class called <code>TypeEncoder</code> to solve these issues. <code>TypeEncoder</code>s are passed around as implicit parameters to every Frameless method to ensure that the data being manipulated is <code>Encoder</code>. It uses a standard implicit resolution coupled with shapeless&apos; type class derivation mechanism to ensure every that compiling code manipulates encodable data. For example, the <code>java.util.Date</code> example won&apos;t compile with Frameless:</p>
<pre><code class="lang-scala"><span class="hljs-keyword">import</span> frameless.<span class="hljs-type">TypedDataset</span>
<span class="hljs-keyword">import</span> frameless.syntax._
</code></pre>
<pre><code class="lang-scala"><span class="hljs-keyword">val</span> ds: <span class="hljs-type">TypedDataset</span>[<span class="hljs-type">DateRange</span>] = <span class="hljs-type">TypedDataset</span>.create(<span class="hljs-type">Seq</span>(<span class="hljs-type">DateRange</span>(<span class="hljs-keyword">new</span> java.util.<span class="hljs-type">Date</span>, <span class="hljs-keyword">new</span> java.util.<span class="hljs-type">Date</span>)))
<span class="hljs-comment">// error: ds is already defined as value ds</span>
<span class="hljs-comment">// val ds: TypedDataset[DateRange] = TypedDataset.create(Seq(DateRange(new java.util.Date, new java.util.Date)))</span>
<span class="hljs-comment">//     ^^</span>
<span class="hljs-comment">// error: could not find implicit value for parameter encoder: frameless.TypedEncoder[repl.MdocSession.App0.DateRange]</span>
<span class="hljs-comment">// val ds: TypedDataset[DateRange] = TypedDataset.create(Seq(DateRange(new java.util.Date, new java.util.Date)))</span>
<span class="hljs-comment">//                                                      ^</span>
</code></pre>
<p>Type class derivation takes care of recursively constructing (and proving the existence of) <code>TypeEncoder</code>s for case classes. The following works as expected:</p>
<pre><code class="lang-scala"><span class="hljs-keyword">case</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Bar</span>(<span class="hljs-params">d: <span class="hljs-type">Double</span>, s: <span class="hljs-type">String</span></span>)</span>
<span class="hljs-keyword">case</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Foo</span>(<span class="hljs-params">i: <span class="hljs-type">Int</span>, b: <span class="hljs-type">Bar</span></span>)</span>
<span class="hljs-keyword">val</span> ds: <span class="hljs-type">TypedDataset</span>[<span class="hljs-type">Foo</span>] = <span class="hljs-type">TypedDataset</span>.create(<span class="hljs-type">Seq</span>(<span class="hljs-type">Foo</span>(<span class="hljs-number">1</span>, <span class="hljs-type">Bar</span>(<span class="hljs-number">1.1</span>, <span class="hljs-string">&quot;s&quot;</span>))))
<span class="hljs-comment">// ds: TypedDataset[Foo] = [i: int, b: struct&lt;d: double, s: string&gt;]</span>
ds.collect()
<span class="hljs-comment">// res3: frameless.Job[Seq[Foo]] = frameless.Job$$anon$4@2895c183</span>
</code></pre>
<p>But any non-encodable in the case class hierarchy will be detected at compile time:</p>
<pre><code class="lang-scala"><span class="hljs-keyword">case</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">BarDate</span>(<span class="hljs-params">d: <span class="hljs-type">Double</span>, s: <span class="hljs-type">String</span>, t: java.util.<span class="hljs-type">Date</span></span>)</span>
<span class="hljs-keyword">case</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">FooDate</span>(<span class="hljs-params">i: <span class="hljs-type">Int</span>, b: <span class="hljs-type">BarDate</span></span>)</span>
</code></pre>
<pre><code class="lang-scala"><span class="hljs-keyword">val</span> ds: <span class="hljs-type">TypedDataset</span>[<span class="hljs-type">FooDate</span>] = <span class="hljs-type">TypedDataset</span>.create(<span class="hljs-type">Seq</span>(<span class="hljs-type">FooDate</span>(<span class="hljs-number">1</span>, <span class="hljs-type">BarDate</span>(<span class="hljs-number">1.1</span>, <span class="hljs-string">&quot;s&quot;</span>, <span class="hljs-keyword">new</span> java.util.<span class="hljs-type">Date</span>))))
<span class="hljs-comment">// error: ds is already defined as value ds</span>
<span class="hljs-comment">// val ds: TypedDataset[Foo] = TypedDataset.create(Seq(Foo(1, Bar(1.1, &quot;s&quot;))))</span>
<span class="hljs-comment">//     ^^</span>
<span class="hljs-comment">// error: ds is already defined as value ds</span>
<span class="hljs-comment">// val ds: TypedDataset[FooDate] = TypedDataset.create(Seq(FooDate(1, BarDate(1.1, &quot;s&quot;, new java.util.Date))))</span>
<span class="hljs-comment">//     ^^</span>
<span class="hljs-comment">// error: could not find implicit value for parameter encoder: frameless.TypedEncoder[repl.MdocSession.App0.FooDate]</span>
<span class="hljs-comment">// val ds: TypedDataset[FooDate] = TypedDataset.create(Seq(FooDate(1, BarDate(1.1, &quot;s&quot;, new java.util.Date))))</span>
<span class="hljs-comment">//                                                    ^</span>
</code></pre>
<p>It should be noted that once derived, reflection-based <code>Encoder</code>s and implicitly derived <code>TypeEncoder</code>s have identical performance. The derivation mechanism is different, but the objects generated to encode and decode JVM objects in Spark&apos;s internal representation behave the same at runtime.</p>

                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="WorkingWithCsvParquetJson.html" class="navigation navigation-prev " aria-label="Previous page: Working with CSV and Parquet">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="Injection.html" class="navigation navigation-next " aria-label="Next page: Injection: Creating Custom Encoders">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"Typed Encoders in Frameless","level":"1.5","depth":1,"next":{"title":"Injection: Creating Custom Encoders","level":"1.6","depth":1,"path":"Injection.md","ref":"Injection.md","articles":[]},"previous":{"title":"Working with CSV and Parquet","level":"1.4","depth":1,"path":"WorkingWithCsvParquetJson.md","ref":"WorkingWithCsvParquetJson.md","articles":[]},"dir":"ltr"},"config":{"gitbook":"*","theme":"default","variables":{},"plugins":[],"pluginsConfig":{"highlight":{},"search":{},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"fontsettings":{"theme":"white","family":"sans","size":2},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"}},"file":{"path":"TypedEncoder.md","mtime":"2021-06-14T18:28:44.119Z","type":"markdown"},"gitbook":{"version":"3.2.3","time":"2021-06-14T18:50:50.326Z"},"basePath":".","book":{"language":""}});
        });
    </script>
</div>

        
    <script src="gitbook/gitbook.js"></script>
    <script src="gitbook/theme.js"></script>
    
        
        <script src="gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-sharing/buttons.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

